{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "# from category_encoders import HashingEncoder # type: ignore\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3815d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148541 entries, 0 to 148540\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            148541 non-null  int64 \n",
      " 1   name          148455 non-null  object\n",
      " 2   city          148541 non-null  object\n",
      " 3   rating        148455 non-null  object\n",
      " 4   rating_count  148455 non-null  object\n",
      " 5   cost          148410 non-null  object\n",
      " 6   cuisine       148442 non-null  object\n",
      " 7   lic_no        148312 non-null  object\n",
      " 8   link          148541 non-null  object\n",
      " 9   address       148455 non-null  object\n",
      " 10  menu          148541 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_swiggy = pd.read_csv(r\"C:\\Users\\v-dhramaraj\\Desktop\\Python\\Projects\\Assignment4_RestRecomendation\\swiggy.csv\")\n",
    "\n",
    "# print(df_swiggy.info())\n",
    "# print(df_swiggy.head())\n",
    "\n",
    "print(df_swiggy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b0a6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_swiggy = df_swiggy.drop_duplicates()\n",
    "\n",
    "# Convert cost to numeric (remove currency symbols)\n",
    "df_swiggy['cost'] = df_swiggy['cost'].replace('[â‚¹,]', '', regex=True)\n",
    "df_swiggy['cost'] = pd.to_numeric(df_swiggy['cost'], errors='coerce')  # Converts non-numeric values to NaN\n",
    "\n",
    "# Function to clean rating_count values\n",
    "def clean_rating_count(value):\n",
    "    value = str(value).strip()  # Ensure it's a string and remove spaces\n",
    "    \n",
    "    if 'Too Few Ratings' in value:\n",
    "        return 0  # Assign 0 for low-rated restaurants\n",
    "    elif 'K' in value:  # Handle \"1K\" format correctly\n",
    "        numeric_value = value.replace('K', '').strip()\n",
    "        return int(float(numeric_value) * 1000) if numeric_value.replace('.', '', 1).isdigit() else 0\n",
    "    elif '+' in value:  # Handle \"50+ ratings\" or \"1+ ratings\"\n",
    "        numeric_part = value.replace('+', '').replace('ratings', '').strip()\n",
    "        return int(numeric_part) if numeric_part.isdigit() else 0\n",
    "    elif value.isdigit():  # If it's already a pure number\n",
    "        return int(value)\n",
    "    else:\n",
    "        return 0  # Default case for unknown formats\n",
    "\n",
    "# Apply function to clean column\n",
    "df_swiggy['rating_count'] = df_swiggy['rating_count'].apply(clean_rating_count)\n",
    "\n",
    "\n",
    "# Convert rating to numeric (replace '--' with NaN)\n",
    "df_swiggy['rating'] = pd.to_numeric(df_swiggy['rating'], errors='coerce')\n",
    "\n",
    "# Handle missing values efficiently\n",
    "# Fill missing values correctly by explicitly assigning them\n",
    "df_swiggy['cost'] = df_swiggy['cost'].fillna(df_swiggy['cost'].median())\n",
    "df_swiggy['rating'] = df_swiggy['rating'].fillna(df_swiggy['rating'].median())\n",
    "\n",
    "\n",
    "# Drop rows with missing categorical values\n",
    "df_swiggy.dropna(subset=['name', 'city', 'cuisine'], inplace=True)\n",
    "# Remove unnecessary columns\n",
    "df_swiggy.drop(columns=['id', 'link', 'menu'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd947de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Completed! Saved as cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "df_swiggy.to_csv(\"cleaned_data.csv\", index=False)\n",
    "print(\"Data Cleaning Completed! Saved as cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b881202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Frequency Encoding for categorical variables\n",
    "# \"\"\"\n",
    "# Frequency Encoding is a technique used to convert categorical variables into numerical values based on \n",
    "# how often each category appears in the dataset. \n",
    "# Instead of creating a new column for every unique category (like One-Hot Encoding), it replaces each category with its relative frequency, making it more memory-efficient\n",
    "# Example Before Encoding\n",
    "# | city | cuisine | \n",
    "# | Delhi | Chinese | \n",
    "# | Mumbai | Italian | \n",
    "# | Delhi | Indian | \n",
    "# After Encoding\n",
    "# | city | city_freq | cuisine | cuisine_freq | \n",
    "# | Delhi | 0.60 | Chinese | 0.40 | \n",
    "# | Mumbai | 0.40 | Italian | 0.20 | \n",
    "# | Delhi | 0.60 | Indian | 0.20 | \n",
    "\n",
    "# Why Use Frequency Encoding?\n",
    "# -- Memory Efficient: Works well for high-cardinality categorical features (like city names).\n",
    "# -- Captures Importance: More frequent categories get higher values, which can improve machine learning performance.\n",
    "# -- Avoids Overfitting: Compared to One-Hot Encoding, it prevents excessive feature creation.\n",
    "\n",
    "# \"\"\"\n",
    "# # Count Occurrences of Each Category\n",
    "# # .map(df_swiggy['city'].value_counts(normalize=True)) replaces each city name in df_swiggy['city'] with its frequency value, does the same for cuisine.\n",
    "# df_swiggy['city_freq'] = df_swiggy['city'].map(df_swiggy['city'].value_counts(normalize=True)) # calculates how often each city appears in the dataset\n",
    "# df_swiggy['cuisine_freq'] = df_swiggy['cuisine'].map(df_swiggy['cuisine'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39879276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding with sparse output\n",
    "\"\"\" \n",
    "One-Hot Encoding is a technique used to convert categorical variables into numerical form. It creates binary columns for each unique category, where:\n",
    "- 1 represents the presence of the category.\n",
    "- 0 represents absence.\n",
    "For example, city column has [\"Delhi\", \"Mumbai\", \"Chennai\"], One-Hot Encoding will generate: \n",
    "City| Delhi | Mumbai | Chennai | |------------|---------|------|------| \n",
    "    | Delhi | 1       | 0    | 0    | | Mumbai  | 0       | 1    | 0    | | Chennai  | 0       | 0    | 1    |\n",
    "\"\"\"\n",
    "# One-Hot Encoding for 'city' and 'cuisine'\n",
    "df_encoded = pd.get_dummies(df_swiggy, columns=['city', 'cuisine'], dtype=int)\n",
    "\n",
    "# Save encoded dataset\n",
    "df_encoded.to_csv(\"encoded_data.csv\", index=False)\n",
    "\n",
    "# Initialize One-Hot Encoder & Save as Pickle File\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoder.fit(df_swiggy[['city', 'cuisine']])\n",
    "\n",
    "with open(\"encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Verify if the file was created\n",
    "import os\n",
    "print(os.path.exists(\"encoder.pkl\"))  # Should print True\n",
    "print(\"Encoding Completed! Saved as encoded_data.csv & encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Completed! Saved as clustered_data.csv\n",
      "Recommendation system initialized.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Clustering & Recommendation System\n",
    "# Load cleaned dataset for clustering\n",
    "df_encoded = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Ensure only numerical features are used for clustering\n",
    "# Convert to numeric and replace NaN values\n",
    "df_cluster = df_encoded.drop(columns=['city', 'cuisine', 'lic_no','address'])\n",
    "df_cluster = df_cluster.apply(pd.to_numeric, errors='coerce')  # Coerce non-numeric values to NaN\n",
    "df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df_cluster = df_cluster.fillna(df_cluster.median())  # Fill NaN with median values\n",
    "\n",
    "# StandardScaler transforms numerical features so they all have zero mean and unit variance, improving clustering quality.\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "\"\"\" Creates 10 restaurant clusters using K-Means, grouping similar restaurants based on numerical features on similar characteristics.\n",
    "The assigned cluster labels (df_encoded['cluster']) help categorize restaurants into distinct groups.\n",
    "- Purpose: Groups restaurants into clusters based on shared characteristics like cost, cuisine, and rating.\n",
    "- Why K-Means? K-Means finds similarities between restaurants and categorizes them into 10 clusters, making recommendations more structured.\n",
    "- How It Helps: Instead of comparing all restaurants, recommendations can now focus only on those within relevant clusters, improving accuracy.\n",
    "\"\"\"\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "df_encoded['cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Save clustered dataset\n",
    "df_encoded.to_csv(\"clustered_data.csv\", index=False)\n",
    "print(\"Clustering Completed! Saved as clustered_data.csv\")\n",
    "\n",
    "\"\"\"\n",
    "- Purpose: Finds the most similar restaurants based on user input.\n",
    "- Why Cosine Similarity? It measures how close a restaurant's feature vector is to a user's preferences, ensuring relevant matches.\n",
    "- How It Helps: Even within a cluster, cosine similarity ranks restaurants to suggest the most relevant options.\n",
    "\"\"\"\n",
    "\n",
    "# Function to recommend similar restaurants\n",
    "def recommend_restaurants(input_data, top_n=5):\n",
    "    # Convert input_data to a format matching encoded data\n",
    "    input_df = pd.DataFrame([input_data], columns=df_cluster.columns)\n",
    "    \n",
    "    # Standardize user input\n",
    "    input_vector = scaler.transform(input_df)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(input_vector, df_scaled)\n",
    "    \n",
    "    # Get top N recommendations based on similarity scores\n",
    "    recommendations = df_encoded.iloc[similarities.argsort()[0][-top_n:]]\n",
    "    \n",
    "    return recommendations[['name', 'city', 'rating', 'cost', 'cuisine']]\n",
    "\n",
    "print(\"Recommendation system initialized.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
